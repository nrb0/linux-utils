#!/usr/bin/python3

from dataclasses import dataclass
from datetime import datetime, timedelta
from desktop_notifier import DesktopNotifier
from pathlib import Path

import argparse
import json
import logging
import os
import shutil
import subprocess
import sys

#-------------------------------------------------------------------------------

# Global names
AppName = 'copy-saves'
Manufacturer = 'nrbo'

# Global paths
userHomeDirectory = Path(os.getenv("HOME"))
userConfigDirectory = userHomeDirectory / ".config"
manufacturerConfigDirectory = userConfigDirectory / "nrbo"
appConfigDirectory = manufacturerConfigDirectory / AppName
appConfigFile = appConfigDirectory / "config.json"
appLogFile = appConfigDirectory / (AppName + ".log")

# Global variables
backupsTag = "backups"
destinationTag = "destination"
nameTag = "name"
sourceTag = "source"
rcloneConfigurationTag = "rclone-config"
remoteTag = "remote"
sftpPathOverrideTag = "sftp-path-override"

dateFormat = "%Y-%m-%d-%H-%M-%S"

notifier = DesktopNotifier()

isDryRun = False

@dataclass
class RCloneResult:
    hasCopied: bool
    isSuccessful: bool
    mustResync: bool

#-------------------------------------------------------------------------------

def readConfig():
    if not appConfigFile.exists():
        return {}

    with open(appConfigFile, 'r') as openedFile:
        jsonObject = json.load(openedFile)
        return jsonObject

    return {}

#-------------------------------------------------------------------------------

def writeConfig():
    jsonObject = json.dumps(globalConfiguration, indent=4)
    with open(appConfigFile, "w") as outputFile:
        outputFile.write(jsonObject)


#-------------------------------------------------------------------------------

# Create app directory
appConfigDirectory.mkdir(parents=True, exist_ok=True)
globalConfiguration = readConfig()

# Create logger
log = logging.getLogger(AppName)
log.setLevel(logging.DEBUG)

# Create formatter and add it to the handlers
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

# Create file handler which logs even debug messages
fileHandler = logging.FileHandler(appLogFile)
fileHandler.setLevel(logging.DEBUG)
fileHandler.setFormatter(formatter)
log.addHandler(fileHandler)

# Create console handler with a higher log level
consoleHandler = logging.StreamHandler()
consoleHandler.setLevel(logging.ERROR)
consoleHandler.setFormatter(formatter)
log.addHandler(consoleHandler)

#-------------------------------------------------------------------------------

def copyDirectoryWithRsync(sourcePath, destinationPath, printResult=True):
    if isDryRun:
        log.debug('Dry run, ignoring copy')
        return False

    rsyncProcess = subprocess.run(["rsync", "-Pav", sourcePath, destinationPath],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT)

    outputString = str(rsyncProcess.stdout.decode("utf-8"))

    if printResult:
        log.info(outputString)

    hasCopied = False
    lines = outputString.splitlines()
    for line in outputString.splitlines():
        if line.startswith(sourcePath.stem):
            hasCopied = True

    return hasCopied

#-------------------------------------------------------------------------------

def copyDirectoryWithRclone(sourcePath, destinationPath, rcloneConfiguration, withResync=False):
    result = RCloneResult(False, False, False)
    result.hasCopied = False

    if isDryRun:
        log.debug('Dry run, ignoring copy')
        return result

    if not remoteTag in rcloneConfiguration:
        log.error("Missing \'{}\' field in rclone configuration".format(remoteTag))
        log.info("Skipping...")
        return result

    actualDestinationPath = "{}:{}".format(rcloneConfiguration[remoteTag], destinationPath)

    rcloneCommand = ["rclone", "bisync", "-v" ,sourcePath, actualDestinationPath]
    if sftpPathOverrideTag in rcloneConfiguration:
        rcloneCommand.append("--sftp-path-override")
        rcloneCommand.append(rcloneConfiguration[sftpPathOverrideTag])

    if withResync:
        rcloneCommand.append("--resync")

    rcloneProcess = subprocess.run(rcloneCommand, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)

    outputString = str(rcloneProcess.stdout.decode("utf-8"))
    log.info(outputString)

    outputLines = outputString.splitlines()
    result.hasCopied = all(line.find("No changes found") == -1 for line in outputLines)
    result.mustResync = any(line.find("Must run --resync to recover") != -1 in line for line in outputLines)
    if result.mustResync:
        result.isSuccessful = False
    elif any(line.find("Bisync successful") != -1 for line in outputLines):
        result.isSuccessful = True
    else:
        result.isSuccessful = False

    return result

#-------------------------------------------------------------------------------

def processSaves():
    if backupsTag in globalConfiguration:
        backupTasks = globalConfiguration[backupsTag]
        for backupTask in backupTasks:
            processTask(backupTask)

#-------------------------------------------------------------------------------

def processTask(taskConfiguration):
    isMalformed = False
    if not nameTag in taskConfiguration:
        log.error("Missing \'{}\' field in configuration".format(nameTag))
        log.info("Skipping...")
        return

    taskName = taskConfiguration[nameTag]
    log.info("Processing " + taskName)

    if not sourceTag in taskConfiguration:
        log.error("Missing \'{}\' field in configuration".format(sourceTag))
        log.info("Skipping {}".format(taskName))
        return

    if not destinationTag in taskConfiguration:
        log.error("Missing \'{}\' field in configuration".format(destinationTag))
        log.info("Skipping {}".format(taskName))
        return

    sourcePath = Path(taskConfiguration[sourceTag])
    if not sourcePath.exists():
        log.error("Source path does not exist")
        log.error("\"{}\" not found!".format(str(sourcePath)))
        log.info("Skipping {}".format(taskName))
        return

    rcloneConfiguration = taskConfiguration[rcloneConfigurationTag] if rcloneConfigurationTag in taskConfiguration else None

    destinationPath = Path(taskConfiguration[destinationTag])
    if not rcloneConfiguration and not destinationPath.exists():
        log.error("Destination path does not exist")
        log.error("\"{}\" not found!".format(str(destinationPath)))
        log.info("Skipping {}".format(taskName))
        return

    processDirectory(taskName, sourcePath, destinationPath, rcloneConfiguration)

#-------------------------------------------------------------------------------

def processDirectory(taskName, sourcePath, destinationParentPath, rcloneConfiguration):
    log.info("Copying {} to destination".format(taskName))

    if rcloneConfiguration:
        rcloneResult = copyDirectoryWithRclone(sourcePath, destinationParentPath, rcloneConfiguration)

        if (not rcloneResult.isSuccessful) and rcloneResult.mustResync:
            rcloneResult = copyDirectoryWithRclone(sourcePath, destinationParentPath, rcloneConfiguration, True)

        if not rcloneResult.isSuccessful:
            notifier.send_sync(title="copy-saves", message="There was an issue when saving {}".format(taskName))

        if (not rcloneResult.isSuccessful) or rcloneResult.hasCopied:
            log.info("Archiving {}".format(taskName))
            archiveDirectory(taskName, sourcePath)

#-------------------------------------------------------------------------------

def archiveDirectory(taskName, sourcePath):
    if isDryRun:
        return

    backupDirectory = appConfigDirectory / "Backups"
    taskBackupDirectory = backupDirectory / taskName

    nowString = datetime.now().strftime(dateFormat)
    currentBackupDirectory = taskBackupDirectory / nowString
    currentBackupDirectory.mkdir(parents=True, exist_ok=True)

    copyDirectoryWithRsync(sourcePath, currentBackupDirectory, False)
    cleanBackupDirectory(taskBackupDirectory)

#-------------------------------------------------------------------------------

def getDirectoryWithNameBetweenDate(directories, startDate, endDate):
    matchingDirectories = []

    for directory in directories:
        try:
            directoryDate = datetime.strptime(directory.stem, dateFormat)
            if directoryDate >= startDate and directoryDate < endDate:
                matchingDirectories.append(directory)
        except:
            continue

    return matchingDirectories

#-------------------------------------------------------------------------------

# This version only keeps 1 version per-day, with the exception of the current day where everything is kept
def filterDirectories1PerDay(directories):
    now = datetime.now()

    directoriesToKeep = []
    directoriesToRemove = []
    directoriesNotConsidered = []

    directories.sort(reverse=True)

    directoriesWithDate = []
    for directory in directories:
            try:
                directoryDate = datetime.strptime(directory.stem, dateFormat)
                directoriesWithDate.append(directory)
            except:
                continue

    currentEndDate = now.replace(hour = 0, minute = 0, second = 0, microsecond = 0) + timedelta(days=1)
    while(len(directoriesWithDate) != 0):
        startDate = currentEndDate - timedelta(days=1)
        matchingDirectories = getDirectoryWithNameBetweenDate(directoriesWithDate, startDate, currentEndDate)

        if len(matchingDirectories) > 0:
            if currentEndDate > now:
                directoriesToKeep.extend(matchingDirectories)
            else:
                directoriesToKeep.append(matchingDirectories[0])
                directoriesToRemove.extend(matchingDirectories[1:])

        for matchingDirectory in matchingDirectories:
            directoriesWithDate.remove(matchingDirectory)

        currentEndDate -= timedelta(days=1)

    for directory in directories:
        if directory not in directoriesToKeep and directory not in directoriesToRemove:
            directoriesNotConsidered.append(directory)

    return directoriesToKeep, directoriesToRemove, directoriesNotConsidered

#-------------------------------------------------------------------------------

# This version removes directories the further they are in time, past 1 year directories are simply kept
def filterDirectoriesOverTime(directories):
    now = datetime.now()
    dates = [
        now - timedelta(minutes=1),
        now - timedelta(hours=1),
        now - timedelta(days=1),
        now - timedelta(days=30),
        now - timedelta(days=365)
    ]

    directoriesToKeep = []
    directoriesToRemove = []
    directoriesNotConsidered = []

    directories.sort(reverse=True)

    for startDate in dates:
        matchingDirectories = getDirectoryWithNameBetweenDate(directories, startDate, now)
        numDirectories = len(matchingDirectories)
        maxDirectoriesToKeep = 15

        if numDirectories >= maxDirectoriesToKeep:
            step = (numDirectories + (maxDirectoriesToKeep - 1) - 1) // (maxDirectoriesToKeep - 1) # ceil division

            for index in range(0, numDirectories):
                if index % step == 0:
                    directoriesToKeep.append(matchingDirectories[index])
                else:
                    directoriesToRemove.append(matchingDirectories[index])
        elif numDirectories > 0:
            for matchingDirectory in matchingDirectories:
                    directoriesToKeep.append(matchingDirectory)

        for matchingDirectory in matchingDirectories:
            directories.remove(matchingDirectory)

    for directory in directories:
        directoriesNotConsidered.append(directory)

    return directoriesToKeep, directoriesToRemove, directoriesNotConsidered

#-------------------------------------------------------------------------------

def cleanBackupDirectory(backupDirectory):
    backupDirectories = []
    for subfolder in os.scandir(backupDirectory):
        if subfolder.is_dir():
            backupDirectories.append(Path(subfolder.path))

    dirsToKeep, dirsToRemove, dirsNotConsidered = filterDirectories1PerDay(backupDirectories)

    for directory in dirsToRemove:
        log.debug("Removing {}".format(directory.stem))
        shutil.rmtree(directory)

#-------------------------------------------------------------------------------
# MAIN
#-------------------------------------------------------------------------------

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Backs up directories')
    parser.add_argument('--verbose', '-v', action='count', default=0)
    parser.add_argument('--dry-run', dest='dryrun', action='store_true')
    args = parser.parse_args()

    if args.verbose == 1:
        consoleHandler.setLevel(logging.INFO)
    elif args.verbose >= 2:
        consoleHandler.setLevel(logging.DEBUG)

    if args.dryrun:
        isDryRun = True

    log.info("Starting copy-saves")

    processSaves()

    log.info("All copy-saves tasks done!")

    for handler in log.handlers:
        handler.close()
        log.removeFilter(handler)
